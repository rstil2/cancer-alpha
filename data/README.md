# Cancer Alpha Data Directory\n\nThis directory contains all datasets used in the Cancer Alpha project.\n\n## Structure\n\n```\ndata/\n├── raw/           # Original, unprocessed data files\n├── processed/     # Cleaned and preprocessed datasets\n└── external/      # External datasets and genomic data\n```\n\n## Data Sources\n\n### Raw Data (`raw/`)\n- Original datasets as downloaded or received\n- Never modify files in this directory\n- Preserve original data integrity\n\n### Processed Data (`processed/`)\n- Cleaned and preprocessed datasets ready for modeling\n- Output from preprocessing pipelines\n- Standardized formats (CSV, HDF5, Parquet)\n\n### External Data (`external/`)\n- TCGA genomic data\n- Public datasets\n- Reference genomes and annotations\n- Third-party datasets\n\n## Data Formats\n\n- **Tabular Data**: CSV, TSV, Excel formats\n- **Genomic Data**: FASTA, FASTQ, VCF, BED formats\n- **Large Datasets**: HDF5, Parquet for efficient storage\n- **Metadata**: JSON, YAML configuration files\n\n## Data Usage Guidelines\n\n1. **Never commit large data files** (>100MB) to Git\n2. **Use Git LFS** for binary data files when necessary\n3. **Document data sources** and preprocessing steps\n4. **Maintain data versioning** for reproducibility\n5. **Follow GDPR/HIPAA** guidelines for sensitive data\n\n## Data Processing Pipeline\n\n1. Raw data validation and quality checks\n2. Data cleaning and preprocessing\n3. Feature engineering and selection\n4. Data splitting (train/validation/test)\n5. Final dataset preparation for modeling\n
