{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cancer-alpha-preprocessing",
   "metadata": {},
   "source": [
    "# Cancer Alpha: Data Preprocessing Pipeline\n",
    "\n",
    "This notebook demonstrates the complete data preprocessing pipeline for the Cancer Alpha multi-cancer classification system.\n",
    "\n",
    "## Overview\n",
    "- Load TCGA genomic and clinical data\n",
    "- Feature engineering and selection\n",
    "- Data quality assessment\n",
    "- Preprocessing for machine learning\n",
    "\n",
    "## Citation\n",
    "If you use this code, please cite:\n",
    "**Cancer Alpha: A Production-Ready AI System for Multi-Cancer Classification Achieving 95% Balanced Accuracy on Real TCGA Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"Cancer Alpha Data Preprocessing Pipeline\")\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TCGA data\n",
    "data_path = Path('../data/tcga')\n",
    "\n",
    "print(\"Loading TCGA data...\")\n",
    "tcga_mutation = np.load(data_path / 'tcga_mutation.npy')\n",
    "tcga_clinical = np.load(data_path / 'tcga_clinical.npy')\n",
    "tcga_labels = np.load(data_path / 'tcga_labels.npy')\n",
    "\n",
    "print(f\"Mutation data shape: {tcga_mutation.shape}\")\n",
    "print(f\"Clinical data shape: {tcga_clinical.shape}\")\n",
    "print(f\"Labels shape: {tcga_labels.shape}\")\n",
    "\n",
    "# Cancer types mapping\n",
    "cancer_types = {\n",
    "    0: 'BRCA', 1: 'LUAD', 2: 'COAD', 3: 'PRAD',\n",
    "    4: 'STAD', 5: 'KIRC', 6: 'HNSC', 7: 'LIHC'\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "n_samples = tcga_mutation.shape[0]\n",
    "mutation_cols = [f'gene_{i}' for i in range(tcga_mutation.shape[1])]\n",
    "clinical_cols = [f'clinical_{i}' for i in range(tcga_clinical.shape[1])]\n",
    "\n",
    "df_mutation = pd.DataFrame(tcga_mutation, columns=mutation_cols)\n",
    "df_clinical = pd.DataFrame(tcga_clinical, columns=clinical_cols)\n",
    "df_labels = pd.DataFrame(tcga_labels, columns=['cancer_type'])\n",
    "\n",
    "# Combine all features\n",
    "df_combined = pd.concat([df_mutation, df_clinical, df_labels], axis=1)\n",
    "\n",
    "print(f\"\\nCombined dataset shape: {df_combined.shape}\")\n",
    "print(f\"Cancer type distribution:\")\n",
    "for i, cancer in cancer_types.items():\n",
    "    count = (df_combined['cancer_type'] == i).sum()\n",
    "    print(f\"  {cancer}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"Performing feature engineering...\")\n",
    "\n",
    "# Create mutation burden features\n",
    "df_combined['total_mutations'] = df_mutation.sum(axis=1)\n",
    "df_combined['mutation_rate'] = df_combined['total_mutations'] / df_mutation.shape[1]\n",
    "df_combined['unique_genes_mutated'] = (df_mutation > 0).sum(axis=1)\n",
    "\n",
    "# Key cancer genes (based on manuscript)\n",
    "key_genes = ['TP53', 'KRAS', 'PIK3CA', 'APC', 'EGFR', 'BRCA1', 'BRCA2']\n",
    "# Simulate key gene positions (in real implementation, these would be mapped)\n",
    "key_gene_positions = [0, 15, 23, 41, 67, 89, 90]  # Example positions\n",
    "\n",
    "for i, gene in enumerate(key_genes):\n",
    "    if key_gene_positions[i] < df_mutation.shape[1]:\n",
    "        df_combined[f'{gene}_mutation'] = df_mutation.iloc[:, key_gene_positions[i]]\n",
    "\n",
    "print(f\"Added {len(key_genes)} key cancer gene features\")\n",
    "print(f\"Total features after engineering: {df_combined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using Mutual Information\n",
    "print(\"Performing feature selection...\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df_combined.drop(['cancer_type'], axis=1)\n",
    "y = df_combined['cancer_type']\n",
    "\n",
    "# Handle missing values with KNN imputation\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Calculate mutual information scores\n",
    "mi_scores = mutual_info_classif(X_imputed, y, random_state=42)\n",
    "mi_scores = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Select top 150 features (as mentioned in manuscript)\n",
    "top_150_features = mi_scores.head(150).index.tolist()\n",
    "\n",
    "print(f\"Selected top 150 features from {len(mi_scores)} total features\")\n",
    "print(f\"\\nTop 10 features by mutual information:\")\n",
    "for i, (feature, score) in enumerate(mi_scores.head(10).items()):\n",
    "    print(f\"{i+1:2d}. {feature}: {score:.4f}\")\n",
    "\n",
    "# Create final feature set\n",
    "X_selected = X_imputed[top_150_features]\n",
    "print(f\"\\nFinal feature matrix shape: {X_selected.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-scaling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scaling\n",
    "print(\"Scaling features using RobustScaler...\")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_selected.columns)\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"Scaled feature matrix shape: {X_scaled.shape}\")\n",
    "print(f\"Label distribution after encoding:\")\n",
    "unique, counts = np.unique(y_encoded, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    cancer_name = cancer_types[label]\n",
    "    print(f\"  {label} ({cancer_name}): {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-processed-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data and preprocessing objects\n",
    "print(\"Saving processed data...\")\n",
    "\n",
    "output_path = Path('../models')\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Save processed data\n",
    "X_scaled.to_csv(output_path / 'X_processed.csv', index=False)\n",
    "pd.DataFrame(y_encoded, columns=['cancer_type']).to_csv(output_path / 'y_processed.csv', index=False)\n",
    "\n",
    "# Save preprocessing objects\n",
    "with open(output_path / 'imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(imputer, f)\n",
    "\n",
    "with open(output_path / 'scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open(output_path / 'label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Save feature names and metadata\n",
    "metadata = {\n",
    "    'n_samples': int(X_scaled.shape[0]),\n",
    "    'n_features': int(X_scaled.shape[1]),\n",
    "    'feature_names': top_150_features,\n",
    "    'cancer_types': cancer_types,\n",
    "    'preprocessing_steps': [\n",
    "        'KNN Imputation (k=5)',\n",
    "        'Mutual Information Feature Selection (top 150)',\n",
    "        'Robust Scaling',\n",
    "        'Label Encoding'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(output_path / 'preprocessing_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Processed data saved to: {output_path}\")\n",
    "print(f\"Final dataset: {X_scaled.shape[0]} samples, {X_scaled.shape[1]} features, {len(np.unique(y_encoded))} cancer types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Cancer type distribution\n",
    "cancer_counts = pd.Series(y_encoded).map(cancer_types).value_counts()\n",
    "axes[0, 0].bar(cancer_counts.index, cancer_counts.values)\n",
    "axes[0, 0].set_title('Cancer Type Distribution')\n",
    "axes[0, 0].set_ylabel('Number of Samples')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Feature importance (top 20)\n",
    "top_20_mi = mi_scores.head(20)\n",
    "axes[0, 1].barh(range(len(top_20_mi)), top_20_mi.values)\n",
    "axes[0, 1].set_yticks(range(len(top_20_mi)))\n",
    "axes[0, 1].set_yticklabels(top_20_mi.index)\n",
    "axes[0, 1].set_title('Top 20 Features by Mutual Information')\n",
    "axes[0, 1].set_xlabel('Mutual Information Score')\n",
    "\n",
    "# Mutation burden distribution\n",
    "mutation_burden = df_combined['total_mutations']\n",
    "axes[1, 0].hist(mutation_burden, bins=30, alpha=0.7)\n",
    "axes[1, 0].set_title('Distribution of Mutation Burden')\n",
    "axes[1, 0].set_xlabel('Total Mutations per Sample')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Missing data heatmap (before imputation)\n",
    "missing_data = X.isnull().sum().head(50)\n",
    "axes[1, 1].bar(range(len(missing_data)), missing_data.values)\n",
    "axes[1, 1].set_title('Missing Data (First 50 Features)')\n",
    "axes[1, 1].set_xlabel('Feature Index')\n",
    "axes[1, 1].set_ylabel('Missing Values Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / 'preprocessing_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Data preprocessing visualization complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
